---
title: "standards_recovery"
output: html_document
date: "2024-10-15"
---
```{r}
standardMasses = c(
124.0807302,
136.1463818,
155.0897,
176.1583118,
204.1441423,
218.0657781,
235.148076,
275.2346132,
284.2491156,
300.049067,
304.2069,
127.073232,
130.1092854,
135.06709,
136.051099,
136.112637,
152.071164,
172.133771,
207.149747,
212.118787,
233.024854,
237.102795,
242.143948,
250.06503,
254.059949,
268.191281,
277.101743,
278.190884,
278.212033,
308.152982,
325.171628,
346.122556,
389.163205,
285.185,
423.170041,
436.234891,
559.260831,
734.468517,
748.484167
)


```

```{r}
processPeak = function(filename, targetMasses){
  lenMass = length(targetMasses)
  tmpFeaturelist = read.csv(filename)
  MZlimit_lower = tmpFeaturelist$mz - tmpFeaturelist$mzUncertainty
  MZlimit_upper = tmpFeaturelist$mz + tmpFeaturelist$mzUncertainty
  returnVec = rep(-1, lenMass + 1) # empty field for name
  
  for (i in 1:lenMass) {
    targetMass = targetMasses[i]
    lower_ok = MZlimit_lower < targetMass
    upper_ok = MZlimit_upper > targetMass
    returnVec[i + 1] = sum(lower_ok & upper_ok) # total number of possible matches for this mass
  }
  
  return(returnVec) # vector containing the number of possible hits for all masses, in order
}
```

```{r}
result_table = data.frame(file = "None")
for (i in 2:(length(standardMasses) + 1)) {
  result_table[1,i] = 0
}
filenames = read.csv("~/Work/Messdaten/Selina_Daten/eval_varied_ppm/filenames.txt")
filenames = filenames[,1]

for (i in 1:length(filenames)) {
  name = paste0("~/Work/Messdaten/Selina_Daten/eval_varied_ppm/", filenames[i])
  result = processPeak(name, standardMasses)
  result_table = rbind(result_table, result)
  result_table$file[i+1] = filenames[i] # first row is empty due to initialization
}

result_table = result_table[-1,]

result_table$sumZero = 0
result_table$sumOnce = 0
result_table$sumMore = 0

for (i in 1:length(filenames)) {
  zcount = 0
  ocount = 0
  mcount = 0
  
  for (j in 2:(length(standardMasses) + 1)) {
    if (result_table[i,j] == 0){
      zcount = zcount + 1
    } else if (result_table[i,j] == 1){
      ocount = ocount + 1
    }else if (result_table[i,j] > 1){
      mcount = mcount + 1
    }
  }
  result_table$sumZero[i] = zcount
  result_table$sumOnce[i] = ocount
  result_table$sumMore[i] = mcount
}
```

```{r create combined FL}
standardsTable = function(filename, standards, ppm){
  # results per dataset
  n = length(standards)
  matchingFeatures = data.frame(std_mass = -1, foundMZ = -1, foundRT = -1, 
                                foundInt = -1, otherMatches = -1)
  tmpData = read.csv(paste0("~/Work/Messdaten/Selina_Daten/eval_varied_ppm/", filename))
  for (i in 1:n) {
    select = tmpData[which(tmpData$mz > (standards[i] - 10e-6 * ppm * tmpData$mz)),]
    select = select[which(select$mz < (standards[i] + 10e-6 * ppm * select$mz)),]
    if(length(select[,1]) == 0){

      matchingFeatures = rbind(matchingFeatures, c(standards[i], 0, -1, 0, 0))
    } else {
      matchingFeatures = rbind(matchingFeatures, 
                             data.frame(std_mass = standards[i], foundMZ = select$mz, 
                                        foundRT = select$retentionTime, foundInt = select$height,
                                        otherMatches = length(select$mz) - 1))
    }
    
  }
  matchingFeatures$filename = filename
  matchingFeatures$matchPPM = ppm
  return(matchingFeatures[-1,]) # return all features that could be standard compunds (by mass)
}

elimination = function(matchGroup, toleranceRT){ # only works if not-founds are not included
  if(length(unique(matchGroup$std_mass)) != 1){
    return(NA)
  }
  # one group ends if it would contain the same file twice
  eliminated = data.frame(filename = unique(matchGroup$filename), found = FALSE)
  groupBreaks = c(1)
  matchGroup = matchGroup[order(matchGroup$retentionTime),]
  
  for (i in 1:length(matchGroup$mz)) {
    namePos = which(eliminated$filename == matchGroup$filename[i])
    if(eliminated$found[namePos]) {
      groupBreaks = rbind(groupBreaks, i)
      eliminated$found = FALSE
      print("case 1 occured")
    } else if((matchGroup$retentionTime[i + 1] - matchGroup$retentionTime[i]) > toleranceRT){
      groupBreaks = rbind(groupBreaks, i)
      eliminated$found = FALSE
    } else {
      eliminated$found[namePos] = TRUE
    }
  }
  groupBreaks = rbind(groupBreaks, length(matchGroup$mz))

  lpos = which(diff(groupBreaks) == max(diff(groupBreaks)))
  rpos = groupBreaks[lpos + 1]
  selector = lpos:rpos
  if (length(lpos) > 1){
    # only return the group with the closest mean mz
    for (i in 2:length(lpos)) {
      selector2 = cbind(selector, lpos[i]:rpos[i])
      if (abs(mean(matchGroup$mz[selector]) - matchGroup$std_mass[1]) >
          abs(mean(matchGroup$mz[selector2]) - matchGroup$std_mass[1])
          ){
        # the second dataset is a better fit, since it has a lower mean deviation from the standard
        selector = selector2
      }
    }
  }
  resultGroup = matchGroup[selector,] %>% summarise(std_mz = first(std_mz), 
                                                    meanMZ = mean(mz), 
                                                    sdevMZ = sd(mz),
                                                    meanRT = mean(retentionTime), 
                                                    sdevRT = sd(retentionTime),
                                                    meanInt = mean(height),
                                                    sdevInt = sd(height),
                                                    selectedCount = length(selector),
                                                    totalCount = length(matchGroup$mz),
                                                    leftBehind = length(eliminated$found) - length(selector)
                                                    )
  
  

  return(resultGroup)
}
```

```{r}
matchingFeatures = data.frame(std_mass = -1, foundMZ = -1, foundRT = -1, 
                                foundInt = -1, otherMatches = -1, filename = "none", matchPPM = 0)
for (name in filenames) {
  matchingFeatures = rbind(matchingFeatures, standardsTable(name, standardMasses, 10))
}
matchingFeatures = matchingFeatures[-1,]
```

```{r}
matchingFeatures = matchingFeatures[order(matchingFeatures$std_mass),]

```

